{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Kkma\n",
    "from tqdm import tqdm \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wer import *\n",
    "import pickle as pkl\n",
    "merge_csv = pd.read_csv(\"merge_output.csv\", encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()\n",
    "file_list = merge_csv.iloc[:, 0].to_list()\n",
    "input_text = merge_csv.iloc[:, 1].to_list()\n",
    "output_text = merge_csv.iloc[:, 2].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['쿠폰과 다른 할인 중복 가능한가요',\n",
       " '쿠폰으로 중복 할인이 되나요',\n",
       " '초보 운전인데 주차하기 어려운 거 드릴까요',\n",
       " '토요일 점심 세 명 예약 할 수 있나요',\n",
       " '메뉴도 예약할 수 있나요',\n",
       " '런치 타임에도 예약을 받으시나요',\n",
       " '주말 예약이 가능한가요',\n",
       " '1시 예약 가능한가요',\n",
       " '저녁 7시에 가려고 하는데요 여덟 명 예약 가능한가요',\n",
       " '예약하고 가야 하나요']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[110:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['쿠폰과 다른 할인 중복가능한가요',\n",
       " '쿠폰으로 중복할인이 되나요?',\n",
       " '초보운전인데 주차하기 어려운 구조일까요?',\n",
       " '토요일 점심 3명 예약할 수 있나요?',\n",
       " '메뉴도 예약할 수 있나요?',\n",
       " '런치타임에도 예약을 받으시나요?',\n",
       " '주말 예약이 가능한가요?',\n",
       " '한 시 예약 가능한가요?',\n",
       " '저녁 7시에 가려고 하는데요, 8명 예약가능한가요?',\n",
       " '예약하고 가야하나요?']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text[110:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def make_only_text(sentence):\n",
    "    return re.compile('[^ㄱ-ㅎ|ㅏ-ㅣ|가-힣|\\s|a-z|A-Z|0-9]+').sub('', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "장애인 주차 구역이 따로 마련되어 있나요?\n",
      "['장애인', '주차', '구역', '이', '따로', '마련', '되', '어', '있', '나요']\n"
     ]
    }
   ],
   "source": [
    "print(output_text[14462])\n",
    "print(kkma.morphs(make_only_text(output_text[14462])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60867\n"
     ]
    }
   ],
   "source": [
    "print(len(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60867it [00:00, 132069.43it/s]\n"
     ]
    }
   ],
   "source": [
    "inp_text = []\n",
    "oup_text = []\n",
    "file_name = []\n",
    "inp_vocab = set()\n",
    "oup_vocab = set()\n",
    "i=0\n",
    "for inp_sent, oup_sent in tqdm(zip(input_text, output_text)):\n",
    "    \n",
    "    if len(inp_sent) <= 5 or inp_sent ==\"('None text', 0)\":\n",
    "        continue\n",
    "    file_name.append('./voice_signal/' + file_list[i][:-3] + 'pkl')\n",
    "    i+=1\n",
    "    inp_sent = kkma.morphs(make_only_text(inp_sent))\n",
    "    oup_sent = kkma.morphs(make_only_text(oup_sent))\n",
    "    inp_text.append(inp_sent)\n",
    "    oup_text.append(oup_sent)\n",
    "    inp_vocab.update(inp_sent)\n",
    "    oup_vocab.update(oup_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60438\n"
     ]
    }
   ],
   "source": [
    "print(len(inp_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_vocab = ['<p>', '<s>', '<e>'] + list(inp_vocab)\n",
    "oup_vocab = ['<p>', '<s>', '<e>'] + list(oup_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_num2char = {i:word for i,word in enumerate(inp_vocab)}\n",
    "inp_char2num = {word:i for i,word in enumerate(inp_vocab)}\n",
    "\n",
    "oup_num2char = {i:word for i,word in enumerate(oup_vocab)}\n",
    "oup_char2num = {word:i for i,word in enumerate(oup_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_char2num['<s>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60438it [00:00, 171734.92it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "inp_numsent = []\n",
    "oup_numsent = []\n",
    "\n",
    "for inp_sent, oup_sent in tqdm(zip(inp_text, oup_text)):\n",
    "    inp_sent = [inp_char2num['<s>']] + [inp_char2num[word] for word in inp_sent] + [inp_char2num['<e>']]\n",
    "    oup_sent = [oup_char2num['<s>']] + [oup_char2num[word] for word in oup_sent] + [oup_char2num[\"<e>\"]]\n",
    "    \n",
    "    inp_numsent.append(inp_sent)\n",
    "    oup_numsent.append(oup_sent)\n",
    "    \n",
    "    step_max_len = len(inp_sent) if len(inp_sent) > len(oup_sent) else len(oup_sent)\n",
    "    max_len = max_len if max_len > step_max_len  else step_max_len\n",
    "    \n",
    "inp_numsent = pad_sequences(inp_numsent, max_len, padding='post')\n",
    "oup_numsent = pad_sequences(oup_numsent, max_len, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open voice_signal/c.zip, voice_signal/c.zip.zip or voice_signal/c.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip voice_signal/c.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = []\n",
    "for file in file_name:\n",
    "    with open(file, 'rb') as f:\n",
    "        pkl_file.append(pkl.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, dev_input, train_output, dev_output = train_test_split(inp_numsent, oup_numsent, test_size = 0.2, random_state = 255)\n",
    "val_input, test_input, val_output, test_output = train_test_split(dev_input, dev_output, test_size = 0.5, random_state = 255)\n",
    "test_input = [[inp_num2char[word] for word in sentence if inp_num2char[word] not in ['<p>', '<e>', '<s>']] for sentence in test_input]\n",
    "test_output = [[oup_num2char[word] for word in sentence if oup_num2char[word] not in ['<p>', '<e>', '<s>']] for sentence in test_output]\n",
    "wer_score = 0\n",
    "for inp_sent, tar_sent in zip(test_input, test_output):\n",
    "    wer_score += wer(inp_sent, tar_sent)\n",
    "print(i, wer_score/len(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['주소', '는', '마포구', '와우', '산로', '22', '길', '20', '28', '이', 'ㅂ니다']\n",
      "['주소', '는', '마포구', '와우', '산로', '22', '길', '2028', '이', 'ㅂ니다']\n"
     ]
    }
   ],
   "source": [
    "print(test_input[2])\n",
    "print(test_output[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, dev_input, train_output, dev_output = train_test_split(inp_numsent, oup_numsent, test_size = 0.2, random_state = 255)\n",
    "val_input, test_input, val_output, test_output = train_test_split(dev_input, dev_output, test_size = 0.5, random_state = 255)\n",
    "\n",
    "train_voice, dev_voice = train_test_split(pkl_file, test_size = 0.2, random_state = 255)\n",
    "val_voice, test_voice = train_test_split(dev_voice, test_size = 0.5, random_state = 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./preprocessed_data/train_text_input.pkl', 'wb') as f:\n",
    "    pkl.dump(train_input, f)\n",
    "with open('./preprocessed_data/train_text_output.pkl', 'wb') as f:\n",
    "    pkl.dump(train_output, f)\n",
    "with open('./preprocessed_data/val_text_input.pkl', 'wb') as f:\n",
    "    pkl.dump(val_input, f)\n",
    "with open('./preprocessed_data/val_text_output.pkl', 'wb') as f:\n",
    "    pkl.dump(val_output, f)\n",
    "with open('./preprocessed_data/test_text_input.pkl', 'wb') as f:\n",
    "    pkl.dump(test_input, f)\n",
    "with open('./preprocessed_data/test_text_output.pkl', 'wb') as f:\n",
    "    pkl.dump(test_output, f)\n",
    "with open('./preprocessed_data/train_voice_input.pkl', 'wb') as f:\n",
    "    pkl.dump(train_voice, f)\n",
    "with open('./preprocessed_data/val_voice_input.pkl', 'wb') as f:\n",
    "    pkl.dump(val_voice, f)\n",
    "with open('./preprocessed_data/test_voice_input.pkl', 'wb') as f:\n",
    "    pkl.dump(test_voice, f)\n",
    "    \n",
    "with open('./preprocessed_data/inp_num2char.pkl', 'wb') as f:\n",
    "    pkl.dump(inp_num2char, f)\n",
    "with open('./preprocessed_data/inp_char2num.pkl', 'wb') as f:\n",
    "    pkl.dump(inp_char2num, f)\n",
    "with open('./preprocessed_data/oup_num2char.pkl', 'wb') as f:\n",
    "    pkl.dump(oup_num2char, f)\n",
    "with open('./preprocessed_data/oup_char2num.pkl', 'wb') as f:\n",
    "    pkl.dump(oup_char2num, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
